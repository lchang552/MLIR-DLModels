// ResNet50 model with placeholder weights, for testing.
// Generated by resnet.ipynb with some manual and automated cleanup for testing.

// RUN: iree-run-mlir --iree-input-type=mhlo --iree-hal-target-backends=dylib-llvm-aot %s --function-input="1x224x224x3xf32" | FileCheck %s
// RUN: [[ $IREE_VULKAN_DISABLE == 1 ]] || (iree-run-mlir --iree-input-type=mhlo --iree-hal-target-backends=vulkan-spirv %s --function-input="1x224x224x3xf32" | FileCheck %s)

module {
  
  func.func @predict(%arg0: tensor<1x224x224x3xf32>) -> tensor<1x1000xf32> attributes {iree.module.export, iree.reflection = {abi = "sip", abiv = 1 : i32, sip = "I8!S5!k0_0R3!_0"}} {
    %320 = mhlo.constant dense<0.000000e+00> : tensor<1x112x112x64xf32>
    %321 = mhlo.constant dense<0.000000e+00> : tensor<1x56x56x64xf32>
    %322 = mhlo.constant dense<0.000000e+00> : tensor<1x56x56x256xf32>
    %323 = mhlo.constant dense<0.000000e+00> : tensor<1x28x28x128xf32>
    %324 = mhlo.constant dense<0.000000e+00> : tensor<1x28x28x512xf32>
    %325 = mhlo.constant dense<0.000000e+00> : tensor<1x14x14x256xf32>
    %326 = mhlo.constant dense<0.000000e+00> : tensor<1x14x14x1024xf32>
    %327 = mhlo.constant dense<0.000000e+00> : tensor<1x7x7x512xf32>
    %328 = mhlo.constant dense<0.000000e+00> : tensor<1x7x7x2048xf32>
    %329 = mhlo.constant dense<4.900000e+01> : tensor<1x2048xf32>
    %330 = mhlo.constant dense<0xFF800000> : tensor<f32>
    %331 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    
    %332 = arith.constant dense<0.166666672> : tensor<64xf32>
    %333 = arith.constant dense<2.000000e-01> : tensor<64xf32>
    %334 = arith.constant dense<2.500000e-01> : tensor<64xf32>
    %335 = arith.constant dense<0.333333343> : tensor<64xf32>
    %336 = arith.constant dense<5.000000e-01> : tensor<64xf32>
    %337 = arith.constant dense<1.000000e+00> : tensor<7x7x3x64xf32>
    %338 = arith.constant dense<0.0384615399> : tensor<256xf32>
    %339 = arith.constant dense<4.000000e-02> : tensor<256xf32>
    %340 = arith.constant dense<0.0416666679> : tensor<256xf32>
    %341 = arith.constant dense<0.0434782617> : tensor<256xf32>
    %342 = arith.constant dense<5.000000e-02> : tensor<256xf32>
    %343 = arith.constant dense<0.0526315793> : tensor<1x1x64x256xf32>
    %344 = arith.constant dense<0.0833333358> : tensor<64xf32>
    %345 = arith.constant dense<0.0909090936> : tensor<64xf32>
    %346 = arith.constant dense<1.000000e-01> : tensor<64xf32>
    %347 = arith.constant dense<0.111111112> : tensor<64xf32>
    %348 = arith.constant dense<1.250000e-01> : tensor<64xf32>
    %349 = arith.constant dense<0.142857149> : tensor<1x1x64x64xf32>
    %350 = arith.constant dense<0.055555556> : tensor<64xf32>
    %351 = arith.constant dense<0.0588235296> : tensor<64xf32>
    %352 = arith.constant dense<6.250000e-02> : tensor<64xf32>
    %353 = arith.constant dense<0.0666666701> : tensor<64xf32>
    %354 = arith.constant dense<0.0714285746> : tensor<64xf32>
    %355 = arith.constant dense<0.0769230798> : tensor<3x3x64x64xf32>
    %356 = arith.constant dense<0.0333333351> : tensor<256xf32>
    %357 = arith.constant dense<0.0344827585> : tensor<256xf32>
    %358 = arith.constant dense<0.0357142873> : tensor<256xf32>
    %359 = arith.constant dense<0.0370370373> : tensor<256xf32>
    %360 = arith.constant dense<0.0454545468> : tensor<256xf32>
    %361 = arith.constant dense<0.0476190485> : tensor<1x1x64x256xf32>
    %362 = arith.constant dense<0.027777778> : tensor<64xf32>
    %363 = arith.constant dense<0.0285714287> : tensor<64xf32>
    %364 = arith.constant dense<0.0294117648> : tensor<64xf32>
    %365 = arith.constant dense<0.0303030312> : tensor<64xf32>
    %366 = arith.constant dense<3.125000e-02> : tensor<64xf32>
    %367 = arith.constant dense<0.0322580636> : tensor<1x1x256x64xf32>
    %368 = arith.constant dense<0.0238095243> : tensor<64xf32>
    %369 = arith.constant dense<0.024390243> : tensor<64xf32>
    %370 = arith.constant dense<2.500000e-02> : tensor<64xf32>
    %371 = arith.constant dense<0.025641026> : tensor<64xf32>
    %372 = arith.constant dense<0.0263157897> : tensor<64xf32>
    %373 = arith.constant dense<0.0270270277> : tensor<3x3x64x64xf32>
    %374 = arith.constant dense<0.020833334> : tensor<256xf32>
    %375 = arith.constant dense<0.0212765951> : tensor<256xf32>
    %376 = arith.constant dense<0.0217391308> : tensor<256xf32>
    %377 = arith.constant dense<0.0222222228> : tensor<256xf32>
    %378 = arith.constant dense<0.0227272734> : tensor<256xf32>
    %379 = arith.constant dense<0.0232558139> : tensor<1x1x64x256xf32>
    %380 = arith.constant dense<0.0185185187> : tensor<64xf32>
    %381 = arith.constant dense<0.0188679248> : tensor<64xf32>
    %382 = arith.constant dense<0.0192307699> : tensor<64xf32>
    %383 = arith.constant dense<0.0196078438> : tensor<64xf32>
    %384 = arith.constant dense<2.000000e-02> : tensor<64xf32>
    %385 = arith.constant dense<0.0204081628> : tensor<1x1x256x64xf32>
    %386 = arith.constant dense<0.0166666675> : tensor<64xf32>
    %387 = arith.constant dense<0.0169491526> : tensor<64xf32>
    %388 = arith.constant dense<0.0172413792> : tensor<64xf32>
    %389 = arith.constant dense<0.0175438598> : tensor<64xf32>
    %390 = arith.constant dense<0.0178571437> : tensor<64xf32>
    %391 = arith.constant dense<0.0181818176> : tensor<3x3x64x64xf32>
    %392 = arith.constant dense<0.0151515156> : tensor<256xf32>
    %393 = arith.constant dense<0.0153846154> : tensor<256xf32>
    %394 = arith.constant dense<1.562500e-02> : tensor<256xf32>
    %395 = arith.constant dense<0.0158730168> : tensor<256xf32>
    %396 = arith.constant dense<0.0161290318> : tensor<256xf32>
    %397 = arith.constant dense<0.0163934417> : tensor<1x1x64x256xf32>
    %398 = arith.constant dense<0.0116279069> : tensor<512xf32>
    %399 = arith.constant dense<0.0117647061> : tensor<512xf32>
    %400 = arith.constant dense<0.0119047621> : tensor<512xf32>
    %401 = arith.constant dense<0.0120481923> : tensor<512xf32>
    %402 = arith.constant dense<1.250000e-02> : tensor<512xf32>
    %403 = arith.constant dense<0.0126582282> : tensor<1x1x256x512xf32>
    %404 = arith.constant dense<0.013888889> : tensor<128xf32>
    %405 = arith.constant dense<0.0140845068> : tensor<128xf32>
    %406 = arith.constant dense<0.0142857144> : tensor<128xf32>
    %407 = arith.constant dense<0.0144927539> : tensor<128xf32>
    %408 = arith.constant dense<0.0147058824> : tensor<128xf32>
    %409 = arith.constant dense<0.0149253728> : tensor<1x1x256x128xf32>
    %410 = arith.constant dense<0.012820513> : tensor<128xf32>
    %411 = arith.constant dense<0.012987013> : tensor<128xf32>
    %412 = arith.constant dense<0.0131578948> : tensor<128xf32>
    %413 = arith.constant dense<0.0133333337> : tensor<128xf32>
    %414 = arith.constant dense<0.0135135138> : tensor<128xf32>
    %415 = arith.constant dense<0.01369863> : tensor<3x3x128x128xf32>
    %416 = arith.constant dense<0.0111111114> : tensor<512xf32>
    %417 = arith.constant dense<0.0112359552> : tensor<512xf32>
    %418 = arith.constant dense<0.0113636367> : tensor<512xf32>
    %419 = arith.constant dense<0.0114942528> : tensor<512xf32>
    %420 = arith.constant dense<0.0121951215> : tensor<512xf32>
    %421 = arith.constant dense<0.0123456791> : tensor<1x1x128x512xf32>
    %422 = arith.constant dense<0.010416667> : tensor<128xf32>
    %423 = arith.constant dense<0.0105263162> : tensor<128xf32>
    %424 = arith.constant dense<0.0106382975> : tensor<128xf32>
    %425 = arith.constant dense<0.0107526882> : tensor<128xf32>
    %426 = arith.constant dense<0.0108695654> : tensor<128xf32>
    %427 = arith.constant dense<0.0109890113> : tensor<1x1x512x128xf32>
    %428 = arith.constant dense<0.00980392192> : tensor<128xf32>
    %429 = arith.constant dense<9.900990e-03> : tensor<128xf32>
    %430 = arith.constant dense<0.00999999977> : tensor<128xf32>
    %431 = arith.constant dense<0.0101010101> : tensor<128xf32>
    %432 = arith.constant dense<0.0102040814> : tensor<128xf32>
    %433 = arith.constant dense<0.010309278> : tensor<3x3x128x128xf32>
    %434 = arith.constant dense<0.00925925932> : tensor<512xf32>
    %435 = arith.constant dense<0.00934579409> : tensor<512xf32>
    %436 = arith.constant dense<0.0094339624> : tensor<512xf32>
    %437 = arith.constant dense<9.523810e-03> : tensor<512xf32>
    %438 = arith.constant dense<0.00961538497> : tensor<512xf32>
    %439 = arith.constant dense<0.00970873795> : tensor<1x1x128x512xf32>
    %440 = arith.constant dense<0.00877192988> : tensor<128xf32>
    %441 = arith.constant dense<0.00884955748> : tensor<128xf32>
    %442 = arith.constant dense<0.00892857183> : tensor<128xf32>
    %443 = arith.constant dense<0.00900900922> : tensor<128xf32>
    %444 = arith.constant dense<0.0090909088> : tensor<128xf32>
    %445 = arith.constant dense<0.00917431153> : tensor<1x1x512x128xf32>
    %446 = arith.constant dense<0.00833333377> : tensor<128xf32>
    %447 = arith.constant dense<0.00840336177> : tensor<128xf32>
    %448 = arith.constant dense<0.00847457629> : tensor<128xf32>
    %449 = arith.constant dense<0.00854700897> : tensor<128xf32>
    %450 = arith.constant dense<8.620690e-03> : tensor<128xf32>
    %451 = arith.constant dense<0.00869565178> : tensor<3x3x128x128xf32>
    %452 = arith.constant dense<0.00793650839> : tensor<512xf32>
    %453 = arith.constant dense<8.000000e-03> : tensor<512xf32>
    %454 = arith.constant dense<0.00806451589> : tensor<512xf32>
    %455 = arith.constant dense<0.008130081> : tensor<512xf32>
    %456 = arith.constant dense<0.00819672085> : tensor<512xf32>
    %457 = arith.constant dense<0.00826446246> : tensor<1x1x128x512xf32>
    %458 = arith.constant dense<0.0075757578> : tensor<128xf32>
    %459 = arith.constant dense<0.00763358781> : tensor<128xf32>
    %460 = arith.constant dense<0.0076923077> : tensor<128xf32>
    %461 = arith.constant dense<0.00775193795> : tensor<128xf32>
    %462 = arith.constant dense<7.812500e-03> : tensor<128xf32>
    %463 = arith.constant dense<0.00787401571> : tensor<1x1x512x128xf32>
    %464 = arith.constant dense<0.00724637694> : tensor<128xf32>
    %465 = arith.constant dense<7.299270e-03> : tensor<128xf32>
    %466 = arith.constant dense<0.0073529412> : tensor<128xf32>
    %467 = arith.constant dense<0.00740740728> : tensor<128xf32>
    %468 = arith.constant dense<0.00746268639> : tensor<128xf32>
    %469 = arith.constant dense<0.00751879718> : tensor<3x3x128x128xf32>
    %470 = arith.constant dense<0.0069444445> : tensor<512xf32>
    %471 = arith.constant dense<0.00699300691> : tensor<512xf32>
    %472 = arith.constant dense<0.00704225338> : tensor<512xf32>
    %473 = arith.constant dense<0.00709219835> : tensor<512xf32>
    %474 = arith.constant dense<0.00714285718> : tensor<512xf32>
    %475 = arith.constant dense<0.00719424477> : tensor<1x1x128x512xf32>
    %476 = arith.constant dense<0.00609756075> : tensor<1024xf32>
    %477 = arith.constant dense<0.00613496918> : tensor<1024xf32>
    %478 = arith.constant dense<0.00617283955> : tensor<1024xf32>
    %479 = arith.constant dense<0.00621118024> : tensor<1024xf32>
    %480 = arith.constant dense<0.00632911408> : tensor<1024xf32>
    %481 = arith.constant dense<0.00636942684> : tensor<1x1x512x1024xf32>
    %482 = arith.constant dense<0.00666666683> : tensor<256xf32>
    %483 = arith.constant dense<0.00671140943> : tensor<256xf32>
    %484 = arith.constant dense<0.00675675692> : tensor<256xf32>
    %485 = arith.constant dense<0.00680272094> : tensor<256xf32>
    %486 = arith.constant dense<0.00684931502> : tensor<256xf32>
    %487 = arith.constant dense<0.0068965517> : tensor<1x1x512x256xf32>
    %488 = arith.constant dense<0.00641025649> : tensor<256xf32>
    %489 = arith.constant dense<0.0064516128> : tensor<256xf32>
    %490 = arith.constant dense<0.00649350649> : tensor<256xf32>
    %491 = arith.constant dense<0.00653594779> : tensor<256xf32>
    %492 = arith.constant dense<0.00657894742> : tensor<256xf32>
    %493 = arith.constant dense<0.00662251655> : tensor<3x3x256x256xf32>
    %494 = arith.constant dense<0.00595238106> : tensor<1024xf32>
    %495 = arith.constant dense<0.00598802418> : tensor<1024xf32>
    %496 = arith.constant dense<0.00602409616> : tensor<1024xf32>
    %497 = arith.constant dense<0.00606060587> : tensor<1024xf32>
    %498 = arith.constant dense<6.250000e-03> : tensor<1024xf32>
    %499 = arith.constant dense<0.00628930796> : tensor<1x1x256x1024xf32>
    %500 = arith.constant dense<0.00574712642> : tensor<256xf32>
    %501 = arith.constant dense<0.00578034669> : tensor<256xf32>
    %502 = arith.constant dense<0.00581395347> : tensor<256xf32>
    %503 = arith.constant dense<0.00584795326> : tensor<256xf32>
    %504 = arith.constant dense<0.00588235306> : tensor<256xf32>
    %505 = arith.constant dense<5.917160e-03> : tensor<1x1x1024x256xf32>
    %506 = arith.constant dense<0.00555555569> : tensor<256xf32>
    %507 = arith.constant dense<0.00558659201> : tensor<256xf32>
    %508 = arith.constant dense<0.00561797759> : tensor<256xf32>
    %509 = arith.constant dense<0.00564971752> : tensor<256xf32>
    %510 = arith.constant dense<0.00568181835> : tensor<256xf32>
    %511 = arith.constant dense<0.00571428565> : tensor<3x3x256x256xf32>
    %512 = arith.constant dense<0.00537634408> : tensor<1024xf32>
    %513 = arith.constant dense<0.00540540554> : tensor<1024xf32>
    %514 = arith.constant dense<0.00543478271> : tensor<1024xf32>
    %515 = arith.constant dense<0.00546448072> : tensor<1024xf32>
    %516 = arith.constant dense<0.00549450563> : tensor<1024xf32>
    %517 = arith.constant dense<0.00552486209> : tensor<1x1x256x1024xf32>
    %518 = arith.constant dense<0.00520833349> : tensor<256xf32>
    %519 = arith.constant dense<0.00523560215> : tensor<256xf32>
    %520 = arith.constant dense<0.00526315812> : tensor<256xf32>
    %521 = arith.constant dense<0.00529100513> : tensor<256xf32>
    %522 = arith.constant dense<0.00531914877> : tensor<256xf32>
    %523 = arith.constant dense<0.00534759369> : tensor<1x1x1024x256xf32>
    %524 = arith.constant dense<0.00505050505> : tensor<256xf32>
    %525 = arith.constant dense<0.00507614203> : tensor<256xf32>
    %526 = arith.constant dense<0.00510204071> : tensor<256xf32>
    %527 = arith.constant dense<0.00512820529> : tensor<256xf32>
    %528 = arith.constant dense<0.00515463902> : tensor<256xf32>
    %529 = arith.constant dense<0.00518134702> : tensor<3x3x256x256xf32>
    %530 = arith.constant dense<0.00490196096> : tensor<1024xf32>
    %531 = arith.constant dense<0.00492610829> : tensor<1024xf32>
    %532 = arith.constant dense<0.00495049497> : tensor<1024xf32>
    %533 = arith.constant dense<0.00497512426> : tensor<1024xf32>
    %534 = arith.constant dense<5.000000e-03> : tensor<1024xf32>
    %535 = arith.constant dense<0.00502512557> : tensor<1x1x256x1024xf32>
    %536 = arith.constant dense<0.00476190494> : tensor<256xf32>
    %537 = arith.constant dense<0.00478468882> : tensor<256xf32>
    %538 = arith.constant dense<0.00480769249> : tensor<256xf32>
    %539 = arith.constant dense<0.00483091781> : tensor<256xf32>
    %540 = arith.constant dense<0.00485436898> : tensor<256xf32>
    %541 = arith.constant dense<0.00487804879> : tensor<1x1x1024x256xf32>
    %542 = arith.constant dense<0.00462962966> : tensor<256xf32>
    %543 = arith.constant dense<0.00465116277> : tensor<256xf32>
    %544 = arith.constant dense<0.00467289705> : tensor<256xf32>
    %545 = arith.constant dense<0.00469483575> : tensor<256xf32>
    %546 = arith.constant dense<0.0047169812> : tensor<256xf32>
    %547 = arith.constant dense<0.00473933667> : tensor<3x3x256x256xf32>
    %548 = arith.constant dense<0.00450450461> : tensor<1024xf32>
    %549 = arith.constant dense<0.00452488707> : tensor<1024xf32>
    %550 = arith.constant dense<0.0045454544> : tensor<1024xf32>
    %551 = arith.constant dense<4.566210e-03> : tensor<1024xf32>
    %552 = arith.constant dense<0.00458715577> : tensor<1024xf32>
    %553 = arith.constant dense<0.00460829493> : tensor<1x1x256x1024xf32>
    %554 = arith.constant dense<0.00438596494> : tensor<256xf32>
    %555 = arith.constant dense<0.00440528616> : tensor<256xf32>
    %556 = arith.constant dense<0.00442477874> : tensor<256xf32>
    %557 = arith.constant dense<0.00444444455> : tensor<256xf32>
    %558 = arith.constant dense<0.00446428591> : tensor<256xf32>
    %559 = arith.constant dense<0.00448430516> : tensor<1x1x1024x256xf32>
    %560 = arith.constant dense<0.00427350448> : tensor<256xf32>
    %561 = arith.constant dense<0.00429184549> : tensor<256xf32>
    %562 = arith.constant dense<0.00431034481> : tensor<256xf32>
    %563 = arith.constant dense<0.00432900432> : tensor<256xf32>
    %564 = arith.constant dense<0.00434782589> : tensor<256xf32>
    %565 = arith.constant dense<0.0043668123> : tensor<3x3x256x256xf32>
    %566 = arith.constant dense<0.00416666688> : tensor<1024xf32>
    %567 = arith.constant dense<0.00418410031> : tensor<1024xf32>
    %568 = arith.constant dense<0.00420168089> : tensor<1024xf32>
    %569 = arith.constant dense<0.00421940908> : tensor<1024xf32>
    %570 = arith.constant dense<0.00423728814> : tensor<1024xf32>
    %571 = arith.constant dense<0.00425531901> : tensor<1x1x256x1024xf32>
    %572 = arith.constant dense<0.0040650405> : tensor<256xf32>
    %573 = arith.constant dense<0.00408163248> : tensor<256xf32>
    %574 = arith.constant dense<0.00409836043> : tensor<256xf32>
    %575 = arith.constant dense<0.00411522621> : tensor<256xf32>
    %576 = arith.constant dense<0.00413223123> : tensor<256xf32>
    %577 = arith.constant dense<0.00414937781> : tensor<1x1x1024x256xf32>
    %578 = arith.constant dense<0.0039682542> : tensor<256xf32>
    %579 = arith.constant dense<0.00398406386> : tensor<256xf32>
    %580 = arith.constant dense<4.000000e-03> : tensor<256xf32>
    %581 = arith.constant dense<0.00401606411> : tensor<256xf32>
    %582 = arith.constant dense<0.00403225794> : tensor<256xf32>
    %583 = arith.constant dense<0.0040485831> : tensor<3x3x256x256xf32>
    %584 = arith.constant dense<0.00387596898> : tensor<1024xf32>
    %585 = arith.constant dense<0.00389105058> : tensor<1024xf32>
    %586 = arith.constant dense<3.906250e-03> : tensor<1024xf32>
    %587 = arith.constant dense<0.00392156886> : tensor<1024xf32>
    %588 = arith.constant dense<0.00393700786> : tensor<1024xf32>
    %589 = arith.constant dense<0.00395256933> : tensor<1x1x256x1024xf32>
    %590 = arith.constant dense<0.00359712238> : tensor<2048xf32>
    %591 = arith.constant dense<0.00361010828> : tensor<2048xf32>
    %592 = arith.constant dense<0.00362318847> : tensor<2048xf32>
    %593 = arith.constant dense<0.00363636366> : tensor<2048xf32>
    %594 = arith.constant dense<0.0036764706> : tensor<2048xf32>
    %595 = arith.constant dense<0.00369003695> : tensor<1x1x1024x2048xf32>
    %596 = arith.constant dense<0.0037878789> : tensor<512xf32>
    %597 = arith.constant dense<0.00380228134> : tensor<512xf32>
    %598 = arith.constant dense<0.00381679391> : tensor<512xf32>
    %599 = arith.constant dense<0.00383141753> : tensor<512xf32>
    %600 = arith.constant dense<0.00384615385> : tensor<512xf32>
    %601 = arith.constant dense<0.00386100379> : tensor<1x1x1024x512xf32>
    %602 = arith.constant dense<0.00370370364> : tensor<512xf32>
    %603 = arith.constant dense<0.00371747208> : tensor<512xf32>
    %604 = arith.constant dense<0.0037313432> : tensor<512xf32>
    %605 = arith.constant dense<0.00374531839> : tensor<512xf32>
    %606 = arith.constant dense<0.00375939859> : tensor<512xf32>
    %607 = arith.constant dense<0.00377358496> : tensor<3x3x512x512xf32>
    %608 = arith.constant dense<0.00354609918> : tensor<2048xf32>
    %609 = arith.constant dense<0.00355871883> : tensor<2048xf32>
    %610 = arith.constant dense<0.00357142859> : tensor<2048xf32>
    %611 = arith.constant dense<0.00358422939> : tensor<2048xf32>
    %612 = arith.constant dense<0.00364963501> : tensor<2048xf32>
    %613 = arith.constant dense<0.00366300368> : tensor<1x1x512x2048xf32>
    %614 = arith.constant dense<0.00347222225> : tensor<512xf32>
    %615 = arith.constant dense<0.00348432059> : tensor<512xf32>
    %616 = arith.constant dense<0.00349650346> : tensor<512xf32>
    %617 = arith.constant dense<0.003508772> : tensor<512xf32>
    %618 = arith.constant dense<0.00352112669> : tensor<512xf32>
    %619 = arith.constant dense<0.00353356893> : tensor<1x1x2048x512xf32>
    %620 = arith.constant dense<0.00340136047> : tensor<512xf32>
    %621 = arith.constant dense<0.00341296918> : tensor<512xf32>
    %622 = arith.constant dense<0.00342465751> : tensor<512xf32>
    %623 = arith.constant dense<0.00343642617> : tensor<512xf32>
    %624 = arith.constant dense<0.00344827585> : tensor<512xf32>
    %625 = arith.constant dense<0.00346020772> : tensor<3x3x512x512xf32>
    %626 = arith.constant dense<0.00333333341> : tensor<2048xf32>
    %627 = arith.constant dense<0.00334448158> : tensor<2048xf32>
    %628 = arith.constant dense<0.00335570471> : tensor<2048xf32>
    %629 = arith.constant dense<0.00336700329> : tensor<2048xf32>
    %630 = arith.constant dense<0.00337837846> : tensor<2048xf32>
    %631 = arith.constant dense<0.00338983047> : tensor<1x1x512x2048xf32>
    %632 = arith.constant dense<0.00326797389> : tensor<512xf32>
    %633 = arith.constant dense<0.00327868853> : tensor<512xf32>
    %634 = arith.constant dense<0.00328947371> : tensor<512xf32>
    %635 = arith.constant dense<0.00330033014> : tensor<512xf32>
    %636 = arith.constant dense<0.00331125828> : tensor<512xf32>
    %637 = arith.constant dense<0.00332225906> : tensor<1x1x2048x512xf32>
    %638 = arith.constant dense<0.00320512825> : tensor<512xf32>
    %639 = arith.constant dense<0.00321543403> : tensor<512xf32>
    %640 = arith.constant dense<0.0032258064> : tensor<512xf32>
    %641 = arith.constant dense<0.00323624606> : tensor<512xf32>
    %642 = arith.constant dense<0.00324675324> : tensor<512xf32>
    %643 = arith.constant dense<0.00325732888> : tensor<3x3x512x512xf32>
    %644 = arith.constant dense<0.00314465398> : tensor<2048xf32>
    %645 = arith.constant dense<0.00315457419> : tensor<2048xf32>
    %646 = arith.constant dense<0.00316455704> : tensor<2048xf32>
    %647 = arith.constant dense<0.00317460322> : tensor<2048xf32>
    %648 = arith.constant dense<0.00318471342> : tensor<2048xf32>
    %649 = arith.constant dense<0.00319488812> : tensor<1x1x512x2048xf32>
    %650 = arith.constant dense<3.125000e-03> : tensor<1000xf32>
    %651 = arith.constant dense<0.00313479616> : tensor<2048x1000xf32>
    %652 = "mhlo.pad"(%arg0, %331) {edge_padding_high = dense<[0, 3, 3, 0]> : tensor<4xi64>, edge_padding_low = dense<[0, 3, 3, 0]> : tensor<4xi64>, interior_padding = dense<0> : tensor<4xi64>} : (tensor<1x224x224x3xf32>, tensor<f32>) -> tensor<1x230x230x3xf32>
    %653 = "mhlo.convolution"(%652, %337) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<2> : tensor<2xi64>} : (tensor<1x230x230x3xf32>, tensor<7x7x3x64xf32>) -> tensor<1x112x112x64xf32>
    %654 = "mhlo.broadcast_in_dim"(%336) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<64xf32>) -> tensor<1x112x112x64xf32>
    %655 = mhlo.add %653, %654 : tensor<1x112x112x64xf32>
    %656 = "mhlo.batch_norm_inference"(%655, %335, %334, %333, %332) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x112x112x64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<1x112x112x64xf32>
    %657 = mhlo.maximum %656, %320 : tensor<1x112x112x64xf32>
    %658 = "mhlo.pad"(%657, %331) {edge_padding_high = dense<[0, 1, 1, 0]> : tensor<4xi64>, edge_padding_low = dense<[0, 1, 1, 0]> : tensor<4xi64>, interior_padding = dense<0> : tensor<4xi64>} : (tensor<1x112x112x64xf32>, tensor<f32>) -> tensor<1x114x114x64xf32>
    %659 = "mhlo.reduce_window"(%658, %330) ( {
    ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):  // no predecessors
      %944 = mhlo.maximum %arg1, %arg2 : tensor<f32>
      "mhlo.return"(%944) : (tensor<f32>) -> ()
    }) {window_dimensions = dense<[1, 3, 3, 1]> : tensor<4xi64>, window_strides = dense<[1, 2, 2, 1]> : tensor<4xi64>} : (tensor<1x114x114x64xf32>, tensor<f32>) -> tensor<1x56x56x64xf32>
    %660 = "mhlo.convolution"(%659, %343) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x56x56x64xf32>, tensor<1x1x64x256xf32>) -> tensor<1x56x56x256xf32>
    %661 = "mhlo.broadcast_in_dim"(%342) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x56x56x256xf32>
    %662 = mhlo.add %660, %661 : tensor<1x56x56x256xf32>
    %663 = "mhlo.batch_norm_inference"(%662, %341, %340, %339, %338) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x56x56x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x56x56x256xf32>
    %664 = "mhlo.convolution"(%659, %349) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x56x56x64xf32>, tensor<1x1x64x64xf32>) -> tensor<1x56x56x64xf32>
    %665 = "mhlo.broadcast_in_dim"(%348) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<64xf32>) -> tensor<1x56x56x64xf32>
    %666 = mhlo.add %664, %665 : tensor<1x56x56x64xf32>
    %667 = "mhlo.batch_norm_inference"(%666, %347, %346, %345, %344) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x56x56x64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<1x56x56x64xf32>
    %668 = mhlo.maximum %667, %321 : tensor<1x56x56x64xf32>
    %669 = "mhlo.convolution"(%668, %355) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x56x56x64xf32>, tensor<3x3x64x64xf32>) -> tensor<1x56x56x64xf32>
    %670 = "mhlo.broadcast_in_dim"(%354) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<64xf32>) -> tensor<1x56x56x64xf32>
    %671 = mhlo.add %669, %670 : tensor<1x56x56x64xf32>
    %672 = "mhlo.batch_norm_inference"(%671, %353, %352, %351, %350) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x56x56x64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<1x56x56x64xf32>
    %673 = mhlo.maximum %672, %321 : tensor<1x56x56x64xf32>
    %674 = "mhlo.convolution"(%673, %361) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x56x56x64xf32>, tensor<1x1x64x256xf32>) -> tensor<1x56x56x256xf32>
    %675 = "mhlo.broadcast_in_dim"(%360) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x56x56x256xf32>
    %676 = mhlo.add %674, %675 : tensor<1x56x56x256xf32>
    %677 = "mhlo.batch_norm_inference"(%676, %359, %358, %357, %356) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x56x56x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x56x56x256xf32>
    %678 = mhlo.add %663, %677 : tensor<1x56x56x256xf32>
    %679 = mhlo.maximum %678, %322 : tensor<1x56x56x256xf32>
    %680 = "mhlo.convolution"(%679, %367) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x56x56x256xf32>, tensor<1x1x256x64xf32>) -> tensor<1x56x56x64xf32>
    %681 = "mhlo.broadcast_in_dim"(%366) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<64xf32>) -> tensor<1x56x56x64xf32>
    %682 = mhlo.add %680, %681 : tensor<1x56x56x64xf32>
    %683 = "mhlo.batch_norm_inference"(%682, %365, %364, %363, %362) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x56x56x64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<1x56x56x64xf32>
    %684 = mhlo.maximum %683, %321 : tensor<1x56x56x64xf32>
    %685 = "mhlo.convolution"(%684, %373) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x56x56x64xf32>, tensor<3x3x64x64xf32>) -> tensor<1x56x56x64xf32>
    %686 = "mhlo.broadcast_in_dim"(%372) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<64xf32>) -> tensor<1x56x56x64xf32>
    %687 = mhlo.add %685, %686 : tensor<1x56x56x64xf32>
    %688 = "mhlo.batch_norm_inference"(%687, %371, %370, %369, %368) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x56x56x64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<1x56x56x64xf32>
    %689 = mhlo.maximum %688, %321 : tensor<1x56x56x64xf32>
    %690 = "mhlo.convolution"(%689, %379) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x56x56x64xf32>, tensor<1x1x64x256xf32>) -> tensor<1x56x56x256xf32>
    %691 = "mhlo.broadcast_in_dim"(%378) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x56x56x256xf32>
    %692 = mhlo.add %690, %691 : tensor<1x56x56x256xf32>
    %693 = "mhlo.batch_norm_inference"(%692, %377, %376, %375, %374) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x56x56x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x56x56x256xf32>
    %694 = mhlo.add %679, %693 : tensor<1x56x56x256xf32>
    %695 = mhlo.maximum %694, %322 : tensor<1x56x56x256xf32>
    %696 = "mhlo.convolution"(%695, %385) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x56x56x256xf32>, tensor<1x1x256x64xf32>) -> tensor<1x56x56x64xf32>
    %697 = "mhlo.broadcast_in_dim"(%384) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<64xf32>) -> tensor<1x56x56x64xf32>
    %698 = mhlo.add %696, %697 : tensor<1x56x56x64xf32>
    %699 = "mhlo.batch_norm_inference"(%698, %383, %382, %381, %380) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x56x56x64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<1x56x56x64xf32>
    %700 = mhlo.maximum %699, %321 : tensor<1x56x56x64xf32>
    %701 = "mhlo.convolution"(%700, %391) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x56x56x64xf32>, tensor<3x3x64x64xf32>) -> tensor<1x56x56x64xf32>
    %702 = "mhlo.broadcast_in_dim"(%390) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<64xf32>) -> tensor<1x56x56x64xf32>
    %703 = mhlo.add %701, %702 : tensor<1x56x56x64xf32>
    %704 = "mhlo.batch_norm_inference"(%703, %389, %388, %387, %386) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x56x56x64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<1x56x56x64xf32>
    %705 = mhlo.maximum %704, %321 : tensor<1x56x56x64xf32>
    %706 = "mhlo.convolution"(%705, %397) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x56x56x64xf32>, tensor<1x1x64x256xf32>) -> tensor<1x56x56x256xf32>
    %707 = "mhlo.broadcast_in_dim"(%396) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x56x56x256xf32>
    %708 = mhlo.add %706, %707 : tensor<1x56x56x256xf32>
    %709 = "mhlo.batch_norm_inference"(%708, %395, %394, %393, %392) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x56x56x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x56x56x256xf32>
    %710 = mhlo.add %695, %709 : tensor<1x56x56x256xf32>
    %711 = mhlo.maximum %710, %322 : tensor<1x56x56x256xf32>
    %712 = "mhlo.convolution"(%711, %403) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<2> : tensor<2xi64>} : (tensor<1x56x56x256xf32>, tensor<1x1x256x512xf32>) -> tensor<1x28x28x512xf32>
    %713 = "mhlo.broadcast_in_dim"(%402) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<512xf32>) -> tensor<1x28x28x512xf32>
    %714 = mhlo.add %712, %713 : tensor<1x28x28x512xf32>
    %715 = "mhlo.batch_norm_inference"(%714, %401, %400, %399, %398) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x28x28x512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<1x28x28x512xf32>
    %716 = "mhlo.convolution"(%711, %409) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<2> : tensor<2xi64>} : (tensor<1x56x56x256xf32>, tensor<1x1x256x128xf32>) -> tensor<1x28x28x128xf32>
    %717 = "mhlo.broadcast_in_dim"(%408) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %718 = mhlo.add %716, %717 : tensor<1x28x28x128xf32>
    %719 = "mhlo.batch_norm_inference"(%718, %407, %406, %405, %404) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x28x28x128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %720 = mhlo.maximum %719, %323 : tensor<1x28x28x128xf32>
    %721 = "mhlo.convolution"(%720, %415) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x28x28x128xf32>, tensor<3x3x128x128xf32>) -> tensor<1x28x28x128xf32>
    %722 = "mhlo.broadcast_in_dim"(%414) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %723 = mhlo.add %721, %722 : tensor<1x28x28x128xf32>
    %724 = "mhlo.batch_norm_inference"(%723, %413, %412, %411, %410) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x28x28x128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %725 = mhlo.maximum %724, %323 : tensor<1x28x28x128xf32>
    %726 = "mhlo.convolution"(%725, %421) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x28x28x128xf32>, tensor<1x1x128x512xf32>) -> tensor<1x28x28x512xf32>
    %727 = "mhlo.broadcast_in_dim"(%420) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<512xf32>) -> tensor<1x28x28x512xf32>
    %728 = mhlo.add %726, %727 : tensor<1x28x28x512xf32>
    %729 = "mhlo.batch_norm_inference"(%728, %419, %418, %417, %416) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x28x28x512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<1x28x28x512xf32>
    %730 = mhlo.add %715, %729 : tensor<1x28x28x512xf32>
    %731 = mhlo.maximum %730, %324 : tensor<1x28x28x512xf32>
    %732 = "mhlo.convolution"(%731, %427) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x28x28x512xf32>, tensor<1x1x512x128xf32>) -> tensor<1x28x28x128xf32>
    %733 = "mhlo.broadcast_in_dim"(%426) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %734 = mhlo.add %732, %733 : tensor<1x28x28x128xf32>
    %735 = "mhlo.batch_norm_inference"(%734, %425, %424, %423, %422) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x28x28x128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %736 = mhlo.maximum %735, %323 : tensor<1x28x28x128xf32>
    %737 = "mhlo.convolution"(%736, %433) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x28x28x128xf32>, tensor<3x3x128x128xf32>) -> tensor<1x28x28x128xf32>
    %738 = "mhlo.broadcast_in_dim"(%432) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %739 = mhlo.add %737, %738 : tensor<1x28x28x128xf32>
    %740 = "mhlo.batch_norm_inference"(%739, %431, %430, %429, %428) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x28x28x128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %741 = mhlo.maximum %740, %323 : tensor<1x28x28x128xf32>
    %742 = "mhlo.convolution"(%741, %439) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x28x28x128xf32>, tensor<1x1x128x512xf32>) -> tensor<1x28x28x512xf32>
    %743 = "mhlo.broadcast_in_dim"(%438) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<512xf32>) -> tensor<1x28x28x512xf32>
    %744 = mhlo.add %742, %743 : tensor<1x28x28x512xf32>
    %745 = "mhlo.batch_norm_inference"(%744, %437, %436, %435, %434) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x28x28x512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<1x28x28x512xf32>
    %746 = mhlo.add %731, %745 : tensor<1x28x28x512xf32>
    %747 = mhlo.maximum %746, %324 : tensor<1x28x28x512xf32>
    %748 = "mhlo.convolution"(%747, %445) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x28x28x512xf32>, tensor<1x1x512x128xf32>) -> tensor<1x28x28x128xf32>
    %749 = "mhlo.broadcast_in_dim"(%444) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %750 = mhlo.add %748, %749 : tensor<1x28x28x128xf32>
    %751 = "mhlo.batch_norm_inference"(%750, %443, %442, %441, %440) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x28x28x128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %752 = mhlo.maximum %751, %323 : tensor<1x28x28x128xf32>
    %753 = "mhlo.convolution"(%752, %451) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x28x28x128xf32>, tensor<3x3x128x128xf32>) -> tensor<1x28x28x128xf32>
    %754 = "mhlo.broadcast_in_dim"(%450) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %755 = mhlo.add %753, %754 : tensor<1x28x28x128xf32>
    %756 = "mhlo.batch_norm_inference"(%755, %449, %448, %447, %446) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x28x28x128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %757 = mhlo.maximum %756, %323 : tensor<1x28x28x128xf32>
    %758 = "mhlo.convolution"(%757, %457) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x28x28x128xf32>, tensor<1x1x128x512xf32>) -> tensor<1x28x28x512xf32>
    %759 = "mhlo.broadcast_in_dim"(%456) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<512xf32>) -> tensor<1x28x28x512xf32>
    %760 = mhlo.add %758, %759 : tensor<1x28x28x512xf32>
    %761 = "mhlo.batch_norm_inference"(%760, %455, %454, %453, %452) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x28x28x512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<1x28x28x512xf32>
    %762 = mhlo.add %747, %761 : tensor<1x28x28x512xf32>
    %763 = mhlo.maximum %762, %324 : tensor<1x28x28x512xf32>
    %764 = "mhlo.convolution"(%763, %463) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x28x28x512xf32>, tensor<1x1x512x128xf32>) -> tensor<1x28x28x128xf32>
    %765 = "mhlo.broadcast_in_dim"(%462) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %766 = mhlo.add %764, %765 : tensor<1x28x28x128xf32>
    %767 = "mhlo.batch_norm_inference"(%766, %461, %460, %459, %458) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x28x28x128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %768 = mhlo.maximum %767, %323 : tensor<1x28x28x128xf32>
    %769 = "mhlo.convolution"(%768, %469) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x28x28x128xf32>, tensor<3x3x128x128xf32>) -> tensor<1x28x28x128xf32>
    %770 = "mhlo.broadcast_in_dim"(%468) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %771 = mhlo.add %769, %770 : tensor<1x28x28x128xf32>
    %772 = "mhlo.batch_norm_inference"(%771, %467, %466, %465, %464) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x28x28x128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<1x28x28x128xf32>
    %773 = mhlo.maximum %772, %323 : tensor<1x28x28x128xf32>
    %774 = "mhlo.convolution"(%773, %475) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x28x28x128xf32>, tensor<1x1x128x512xf32>) -> tensor<1x28x28x512xf32>
    %775 = "mhlo.broadcast_in_dim"(%474) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<512xf32>) -> tensor<1x28x28x512xf32>
    %776 = mhlo.add %774, %775 : tensor<1x28x28x512xf32>
    %777 = "mhlo.batch_norm_inference"(%776, %473, %472, %471, %470) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x28x28x512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<1x28x28x512xf32>
    %778 = mhlo.add %763, %777 : tensor<1x28x28x512xf32>
    %779 = mhlo.maximum %778, %324 : tensor<1x28x28x512xf32>
    %780 = "mhlo.convolution"(%779, %481) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<2> : tensor<2xi64>} : (tensor<1x28x28x512xf32>, tensor<1x1x512x1024xf32>) -> tensor<1x14x14x1024xf32>
    %781 = "mhlo.broadcast_in_dim"(%480) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %782 = mhlo.add %780, %781 : tensor<1x14x14x1024xf32>
    %783 = "mhlo.batch_norm_inference"(%782, %479, %478, %477, %476) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %784 = "mhlo.convolution"(%779, %487) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<2> : tensor<2xi64>} : (tensor<1x28x28x512xf32>, tensor<1x1x512x256xf32>) -> tensor<1x14x14x256xf32>
    %785 = "mhlo.broadcast_in_dim"(%486) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %786 = mhlo.add %784, %785 : tensor<1x14x14x256xf32>
    %787 = "mhlo.batch_norm_inference"(%786, %485, %484, %483, %482) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %788 = mhlo.maximum %787, %325 : tensor<1x14x14x256xf32>
    %789 = "mhlo.convolution"(%788, %493) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x256xf32>, tensor<3x3x256x256xf32>) -> tensor<1x14x14x256xf32>
    %790 = "mhlo.broadcast_in_dim"(%492) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %791 = mhlo.add %789, %790 : tensor<1x14x14x256xf32>
    %792 = "mhlo.batch_norm_inference"(%791, %491, %490, %489, %488) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %793 = mhlo.maximum %792, %325 : tensor<1x14x14x256xf32>
    %794 = "mhlo.convolution"(%793, %499) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x256xf32>, tensor<1x1x256x1024xf32>) -> tensor<1x14x14x1024xf32>
    %795 = "mhlo.broadcast_in_dim"(%498) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %796 = mhlo.add %794, %795 : tensor<1x14x14x1024xf32>
    %797 = "mhlo.batch_norm_inference"(%796, %497, %496, %495, %494) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %798 = mhlo.add %783, %797 : tensor<1x14x14x1024xf32>
    %799 = mhlo.maximum %798, %326 : tensor<1x14x14x1024xf32>
    %800 = "mhlo.convolution"(%799, %505) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x1024xf32>, tensor<1x1x1024x256xf32>) -> tensor<1x14x14x256xf32>
    %801 = "mhlo.broadcast_in_dim"(%504) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %802 = mhlo.add %800, %801 : tensor<1x14x14x256xf32>
    %803 = "mhlo.batch_norm_inference"(%802, %503, %502, %501, %500) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %804 = mhlo.maximum %803, %325 : tensor<1x14x14x256xf32>
    %805 = "mhlo.convolution"(%804, %511) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x256xf32>, tensor<3x3x256x256xf32>) -> tensor<1x14x14x256xf32>
    %806 = "mhlo.broadcast_in_dim"(%510) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %807 = mhlo.add %805, %806 : tensor<1x14x14x256xf32>
    %808 = "mhlo.batch_norm_inference"(%807, %509, %508, %507, %506) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %809 = mhlo.maximum %808, %325 : tensor<1x14x14x256xf32>
    %810 = "mhlo.convolution"(%809, %517) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x256xf32>, tensor<1x1x256x1024xf32>) -> tensor<1x14x14x1024xf32>
    %811 = "mhlo.broadcast_in_dim"(%516) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %812 = mhlo.add %810, %811 : tensor<1x14x14x1024xf32>
    %813 = "mhlo.batch_norm_inference"(%812, %515, %514, %513, %512) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %814 = mhlo.add %799, %813 : tensor<1x14x14x1024xf32>
    %815 = mhlo.maximum %814, %326 : tensor<1x14x14x1024xf32>
    %816 = "mhlo.convolution"(%815, %523) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x1024xf32>, tensor<1x1x1024x256xf32>) -> tensor<1x14x14x256xf32>
    %817 = "mhlo.broadcast_in_dim"(%522) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %818 = mhlo.add %816, %817 : tensor<1x14x14x256xf32>
    %819 = "mhlo.batch_norm_inference"(%818, %521, %520, %519, %518) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %820 = mhlo.maximum %819, %325 : tensor<1x14x14x256xf32>
    %821 = "mhlo.convolution"(%820, %529) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x256xf32>, tensor<3x3x256x256xf32>) -> tensor<1x14x14x256xf32>
    %822 = "mhlo.broadcast_in_dim"(%528) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %823 = mhlo.add %821, %822 : tensor<1x14x14x256xf32>
    %824 = "mhlo.batch_norm_inference"(%823, %527, %526, %525, %524) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %825 = mhlo.maximum %824, %325 : tensor<1x14x14x256xf32>
    %826 = "mhlo.convolution"(%825, %535) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x256xf32>, tensor<1x1x256x1024xf32>) -> tensor<1x14x14x1024xf32>
    %827 = "mhlo.broadcast_in_dim"(%534) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %828 = mhlo.add %826, %827 : tensor<1x14x14x1024xf32>
    %829 = "mhlo.batch_norm_inference"(%828, %533, %532, %531, %530) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %830 = mhlo.add %815, %829 : tensor<1x14x14x1024xf32>
    %831 = mhlo.maximum %830, %326 : tensor<1x14x14x1024xf32>
    %832 = "mhlo.convolution"(%831, %541) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x1024xf32>, tensor<1x1x1024x256xf32>) -> tensor<1x14x14x256xf32>
    %833 = "mhlo.broadcast_in_dim"(%540) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %834 = mhlo.add %832, %833 : tensor<1x14x14x256xf32>
    %835 = "mhlo.batch_norm_inference"(%834, %539, %538, %537, %536) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %836 = mhlo.maximum %835, %325 : tensor<1x14x14x256xf32>
    %837 = "mhlo.convolution"(%836, %547) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x256xf32>, tensor<3x3x256x256xf32>) -> tensor<1x14x14x256xf32>
    %838 = "mhlo.broadcast_in_dim"(%546) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %839 = mhlo.add %837, %838 : tensor<1x14x14x256xf32>
    %840 = "mhlo.batch_norm_inference"(%839, %545, %544, %543, %542) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %841 = mhlo.maximum %840, %325 : tensor<1x14x14x256xf32>
    %842 = "mhlo.convolution"(%841, %553) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x256xf32>, tensor<1x1x256x1024xf32>) -> tensor<1x14x14x1024xf32>
    %843 = "mhlo.broadcast_in_dim"(%552) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %844 = mhlo.add %842, %843 : tensor<1x14x14x1024xf32>
    %845 = "mhlo.batch_norm_inference"(%844, %551, %550, %549, %548) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %846 = mhlo.add %831, %845 : tensor<1x14x14x1024xf32>
    %847 = mhlo.maximum %846, %326 : tensor<1x14x14x1024xf32>
    %848 = "mhlo.convolution"(%847, %559) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x1024xf32>, tensor<1x1x1024x256xf32>) -> tensor<1x14x14x256xf32>
    %849 = "mhlo.broadcast_in_dim"(%558) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %850 = mhlo.add %848, %849 : tensor<1x14x14x256xf32>
    %851 = "mhlo.batch_norm_inference"(%850, %557, %556, %555, %554) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %852 = mhlo.maximum %851, %325 : tensor<1x14x14x256xf32>
    %853 = "mhlo.convolution"(%852, %565) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x256xf32>, tensor<3x3x256x256xf32>) -> tensor<1x14x14x256xf32>
    %854 = "mhlo.broadcast_in_dim"(%564) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %855 = mhlo.add %853, %854 : tensor<1x14x14x256xf32>
    %856 = "mhlo.batch_norm_inference"(%855, %563, %562, %561, %560) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %857 = mhlo.maximum %856, %325 : tensor<1x14x14x256xf32>
    %858 = "mhlo.convolution"(%857, %571) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x256xf32>, tensor<1x1x256x1024xf32>) -> tensor<1x14x14x1024xf32>
    %859 = "mhlo.broadcast_in_dim"(%570) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %860 = mhlo.add %858, %859 : tensor<1x14x14x1024xf32>
    %861 = "mhlo.batch_norm_inference"(%860, %569, %568, %567, %566) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %862 = mhlo.add %847, %861 : tensor<1x14x14x1024xf32>
    %863 = mhlo.maximum %862, %326 : tensor<1x14x14x1024xf32>
    %864 = "mhlo.convolution"(%863, %577) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x1024xf32>, tensor<1x1x1024x256xf32>) -> tensor<1x14x14x256xf32>
    %865 = "mhlo.broadcast_in_dim"(%576) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %866 = mhlo.add %864, %865 : tensor<1x14x14x256xf32>
    %867 = "mhlo.batch_norm_inference"(%866, %575, %574, %573, %572) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %868 = mhlo.maximum %867, %325 : tensor<1x14x14x256xf32>
    %869 = "mhlo.convolution"(%868, %583) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x256xf32>, tensor<3x3x256x256xf32>) -> tensor<1x14x14x256xf32>
    %870 = "mhlo.broadcast_in_dim"(%582) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %871 = mhlo.add %869, %870 : tensor<1x14x14x256xf32>
    %872 = "mhlo.batch_norm_inference"(%871, %581, %580, %579, %578) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<1x14x14x256xf32>
    %873 = mhlo.maximum %872, %325 : tensor<1x14x14x256xf32>
    %874 = "mhlo.convolution"(%873, %589) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x14x14x256xf32>, tensor<1x1x256x1024xf32>) -> tensor<1x14x14x1024xf32>
    %875 = "mhlo.broadcast_in_dim"(%588) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %876 = mhlo.add %874, %875 : tensor<1x14x14x1024xf32>
    %877 = "mhlo.batch_norm_inference"(%876, %587, %586, %585, %584) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x14x14x1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1024xf32>) -> tensor<1x14x14x1024xf32>
    %878 = mhlo.add %863, %877 : tensor<1x14x14x1024xf32>
    %879 = mhlo.maximum %878, %326 : tensor<1x14x14x1024xf32>
    %880 = "mhlo.convolution"(%879, %595) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<2> : tensor<2xi64>} : (tensor<1x14x14x1024xf32>, tensor<1x1x1024x2048xf32>) -> tensor<1x7x7x2048xf32>
    %881 = "mhlo.broadcast_in_dim"(%594) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<2048xf32>) -> tensor<1x7x7x2048xf32>
    %882 = mhlo.add %880, %881 : tensor<1x7x7x2048xf32>
    %883 = "mhlo.batch_norm_inference"(%882, %593, %592, %591, %590) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x7x7x2048xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<2048xf32>) -> tensor<1x7x7x2048xf32>
    %884 = "mhlo.convolution"(%879, %601) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<2> : tensor<2xi64>} : (tensor<1x14x14x1024xf32>, tensor<1x1x1024x512xf32>) -> tensor<1x7x7x512xf32>
    %885 = "mhlo.broadcast_in_dim"(%600) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<512xf32>) -> tensor<1x7x7x512xf32>
    %886 = mhlo.add %884, %885 : tensor<1x7x7x512xf32>
    %887 = "mhlo.batch_norm_inference"(%886, %599, %598, %597, %596) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x7x7x512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<1x7x7x512xf32>
    %888 = mhlo.maximum %887, %327 : tensor<1x7x7x512xf32>
    %889 = "mhlo.convolution"(%888, %607) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x7x7x512xf32>, tensor<3x3x512x512xf32>) -> tensor<1x7x7x512xf32>
    %890 = "mhlo.broadcast_in_dim"(%606) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<512xf32>) -> tensor<1x7x7x512xf32>
    %891 = mhlo.add %889, %890 : tensor<1x7x7x512xf32>
    %892 = "mhlo.batch_norm_inference"(%891, %605, %604, %603, %602) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x7x7x512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<1x7x7x512xf32>
    %893 = mhlo.maximum %892, %327 : tensor<1x7x7x512xf32>
    %894 = "mhlo.convolution"(%893, %613) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x7x7x512xf32>, tensor<1x1x512x2048xf32>) -> tensor<1x7x7x2048xf32>
    %895 = "mhlo.broadcast_in_dim"(%612) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<2048xf32>) -> tensor<1x7x7x2048xf32>
    %896 = mhlo.add %894, %895 : tensor<1x7x7x2048xf32>
    %897 = "mhlo.batch_norm_inference"(%896, %611, %610, %609, %608) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x7x7x2048xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<2048xf32>) -> tensor<1x7x7x2048xf32>
    %898 = mhlo.add %883, %897 : tensor<1x7x7x2048xf32>
    %899 = mhlo.maximum %898, %328 : tensor<1x7x7x2048xf32>
    %900 = "mhlo.convolution"(%899, %619) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x7x7x2048xf32>, tensor<1x1x2048x512xf32>) -> tensor<1x7x7x512xf32>
    %901 = "mhlo.broadcast_in_dim"(%618) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<512xf32>) -> tensor<1x7x7x512xf32>
    %902 = mhlo.add %900, %901 : tensor<1x7x7x512xf32>
    %903 = "mhlo.batch_norm_inference"(%902, %617, %616, %615, %614) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x7x7x512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<1x7x7x512xf32>
    %904 = mhlo.maximum %903, %327 : tensor<1x7x7x512xf32>
    %905 = "mhlo.convolution"(%904, %625) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x7x7x512xf32>, tensor<3x3x512x512xf32>) -> tensor<1x7x7x512xf32>
    %906 = "mhlo.broadcast_in_dim"(%624) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<512xf32>) -> tensor<1x7x7x512xf32>
    %907 = mhlo.add %905, %906 : tensor<1x7x7x512xf32>
    %908 = "mhlo.batch_norm_inference"(%907, %623, %622, %621, %620) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x7x7x512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<1x7x7x512xf32>
    %909 = mhlo.maximum %908, %327 : tensor<1x7x7x512xf32>
    %910 = "mhlo.convolution"(%909, %631) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x7x7x512xf32>, tensor<1x1x512x2048xf32>) -> tensor<1x7x7x2048xf32>
    %911 = "mhlo.broadcast_in_dim"(%630) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<2048xf32>) -> tensor<1x7x7x2048xf32>
    %912 = mhlo.add %910, %911 : tensor<1x7x7x2048xf32>
    %913 = "mhlo.batch_norm_inference"(%912, %629, %628, %627, %626) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x7x7x2048xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<2048xf32>) -> tensor<1x7x7x2048xf32>
    %914 = mhlo.add %899, %913 : tensor<1x7x7x2048xf32>
    %915 = mhlo.maximum %914, %328 : tensor<1x7x7x2048xf32>
    %916 = "mhlo.convolution"(%915, %637) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x7x7x2048xf32>, tensor<1x1x2048x512xf32>) -> tensor<1x7x7x512xf32>
    %917 = "mhlo.broadcast_in_dim"(%636) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<512xf32>) -> tensor<1x7x7x512xf32>
    %918 = mhlo.add %916, %917 : tensor<1x7x7x512xf32>
    %919 = "mhlo.batch_norm_inference"(%918, %635, %634, %633, %632) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x7x7x512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<1x7x7x512xf32>
    %920 = mhlo.maximum %919, %327 : tensor<1x7x7x512xf32>
    %921 = "mhlo.convolution"(%920, %643) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<1> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x7x7x512xf32>, tensor<3x3x512x512xf32>) -> tensor<1x7x7x512xf32>
    %922 = "mhlo.broadcast_in_dim"(%642) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<512xf32>) -> tensor<1x7x7x512xf32>
    %923 = mhlo.add %921, %922 : tensor<1x7x7x512xf32>
    %924 = "mhlo.batch_norm_inference"(%923, %641, %640, %639, %638) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x7x7x512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<1x7x7x512xf32>
    %925 = mhlo.maximum %924, %327 : tensor<1x7x7x512xf32>
    %926 = "mhlo.convolution"(%925, %649) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<raw input_batch_dimension = 0, input_feature_dimension = 3, input_spatial_dimensions = [1, 2], kernel_input_feature_dimension = 2, kernel_output_feature_dimension = 3, kernel_spatial_dimensions = [0, 1], output_batch_dimension = 0, output_feature_dimension = 3, output_spatial_dimensions = [1, 2]>, feature_group_count = 1 : i64, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x7x7x512xf32>, tensor<1x1x512x2048xf32>) -> tensor<1x7x7x2048xf32>
    %927 = "mhlo.broadcast_in_dim"(%648) {broadcast_dimensions = dense<3> : tensor<1xi64>} : (tensor<2048xf32>) -> tensor<1x7x7x2048xf32>
    %928 = mhlo.add %926, %927 : tensor<1x7x7x2048xf32>
    %929 = "mhlo.batch_norm_inference"(%928, %647, %646, %645, %644) {epsilon = 1.001000e-05 : f32, feature_index = 3 : i64} : (tensor<1x7x7x2048xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<2048xf32>, tensor<2048xf32>) -> tensor<1x7x7x2048xf32>
    %930 = mhlo.add %915, %929 : tensor<1x7x7x2048xf32>
    %931 = mhlo.maximum %930, %328 : tensor<1x7x7x2048xf32>
    %932 = "mhlo.reduce"(%931, %331) ( {
    ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):  // no predecessors
      %944 = mhlo.add %arg1, %arg2 : tensor<f32>
      "mhlo.return"(%944) : (tensor<f32>) -> ()
    }) {dimensions = dense<[1, 2]> : tensor<2xi64>} : (tensor<1x7x7x2048xf32>, tensor<f32>) -> tensor<1x2048xf32>
    %933 = mhlo.divide %932, %329 : tensor<1x2048xf32>
    %934 = "mhlo.dot"(%933, %651) : (tensor<1x2048xf32>, tensor<2048x1000xf32>) -> tensor<1x1000xf32>
    %935 = "mhlo.broadcast_in_dim"(%650) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<1000xf32>) -> tensor<1x1000xf32>
    %936 = mhlo.add %934, %935 : tensor<1x1000xf32>
    %937 = "mhlo.reduce"(%936, %330) ( {
    ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):  // no predecessors
      %944 = mhlo.maximum %arg1, %arg2 : tensor<f32>
      "mhlo.return"(%944) : (tensor<f32>) -> ()
    }) {dimensions = dense<1> : tensor<1xi64>} : (tensor<1x1000xf32>, tensor<f32>) -> tensor<1xf32>
    %938 = "mhlo.broadcast_in_dim"(%937) {broadcast_dimensions = dense<0> : tensor<1xi64>} : (tensor<1xf32>) -> tensor<1x1000xf32>
    %939 = mhlo.subtract %936, %938 : tensor<1x1000xf32>
    %940 = "mhlo.exponential"(%939) : (tensor<1x1000xf32>) -> tensor<1x1000xf32>
    %941 = "mhlo.reduce"(%940, %331) ( {
    ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):  // no predecessors
      %944 = mhlo.add %arg1, %arg2 : tensor<f32>
      "mhlo.return"(%944) : (tensor<f32>) -> ()
    }) {dimensions = dense<1> : tensor<1xi64>} : (tensor<1x1000xf32>, tensor<f32>) -> tensor<1xf32>
    %942 = "mhlo.broadcast_in_dim"(%941) {broadcast_dimensions = dense<0> : tensor<1xi64>} : (tensor<1xf32>) -> tensor<1x1000xf32>
    %943 = mhlo.divide %940, %942 : tensor<1x1000xf32>
    return %943 : tensor<1x1000xf32>
  }
}

// CHECK: 1x1000xf32=[0.001 0.001 0.001 0.001 0.001
